{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6c7691",
   "metadata": {},
   "source": [
    "# Inteligent Rock-Paper-Scissors Game!\n",
    "### 1- Importing Dependensies & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dcc441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Consider to create a venv with python 3.10 or lower to prevent facing any issues with the libraries'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import torch\n",
    "import random\n",
    "import shutil\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"Python Version:\", sys.version)\n",
    "\"\"\"Consider to create a venv with python 3.10 or lower to prevent facing any issues with the libraries\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc1cec",
   "metadata": {},
   "source": [
    "##### Defining the pathes of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f80fd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(\"Dataset/\")\n",
    "\n",
    "# os.mkdir(\"Dataset/Images/\")\n",
    "# os.mkdir(\"Dataset/Labels/\")\n",
    "# os.mkdir(\"Dataset/Texts/\")\n",
    "\n",
    "# os.mkdir(\"Dataset/Images/Rock/\")\n",
    "# os.mkdir(\"Dataset/Images/Paper/\")\n",
    "# os.mkdir(\"Dataset/Images/Scissors/\")\n",
    "\n",
    "# os.mkdir(\"Dataset/Labels/Rock/\")\n",
    "# os.mkdir(\"Dataset/Labels/Paper/\")\n",
    "# os.mkdir(\"Dataset/Labels/Scissors/\")\n",
    "\n",
    "# os.mkdir(\"Dataset/Texts/Rock/\")\n",
    "# os.mkdir(\"Dataset/Texts/Paper/\")\n",
    "# os.mkdir(\"Dataset/Texts/Scissors/\")\n",
    "\n",
    "images_path = os.path.join(\"Dataset/Images/\")\n",
    "labels_path = os.path.join(\"Dataset/Lables/\")\n",
    "\n",
    "rock_images_path = os.path.join(\"Dataset/Images/Rock/\")\n",
    "paper_images_path = os.path.join(\"Dataset/Images/Paper/\")\n",
    "scissors_images_path = os.path.join(\"Dataset/Images/Scissors/\")\n",
    "\n",
    "rock_labels_path = os.path.join(\"Dataset/Labels/Rock/\")\n",
    "paper_labels_path = os.path.join(\"Dataset/Labels/Paper/\")\n",
    "scissors_labels_path = os.path.join(\"Dataset/Labels/Scissors/\")\n",
    "\n",
    "classes = [{'Name':'Rock', 'id':0}, {'Name':'Paper', 'id':1}, {'Name':'Scissors', 'id':2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf59134",
   "metadata": {},
   "source": [
    "### 2- Capturing Images for dataset \n",
    "###### (No any published dataset will be used - ONLY GATHERED DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ed825",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv.VideoCapture(0)\n",
    " \n",
    "# Change the path for each class everytime\n",
    "path = rock_labels_path\n",
    "\n",
    "# Capture 35 images for each class\n",
    "count = 1\n",
    "while cam.isOpened():\n",
    "    ret, frame = cam.read()\n",
    "    img_path = os.path.join(path, f'{str(uuid.uuid1())}.jpg')\n",
    "    cv.imshow('Camera', frame)\n",
    "    time.sleep(0.2)\n",
    "    if cv.waitKey(1) & 0xFF == ord('c'):\n",
    "        cv.imwrite(img_path, frame)\n",
    "        print(f'Image \"{count}\" captured')\n",
    "        count += 1\n",
    "    elif cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        print('Closing webcam...')\n",
    "        break\n",
    "\n",
    "    if count == 36:\n",
    "        print('\\n35 Images Collected\\nClosing webcam...')\n",
    "        break\n",
    "    \n",
    "cam.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89d8e4",
   "metadata": {},
   "source": [
    "### 3- Use LabelImg to make labels for each image\n",
    "* pip install labelImg\n",
    "* open cmd\n",
    "* type labelImg\n",
    "##### Convert xml files coordinations into text file\n",
    "* arrangement:\n",
    "    * 0. label\n",
    "    * 1. xmin\n",
    "    * 2. ymin\n",
    "    * 3. xmax\n",
    "    * 4. ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caffe806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Also there are some libraries like 'xmltodict' for converting .xml datas into .txt format\"\"\"\n",
    "# pip install xmltodict\n",
    "\n",
    "def xml_to_txt(label_xml, label_path, label_txt, label_id):\n",
    "    for i in range(len(label_xml)):\n",
    "        with open(f'{label_path}{label_xml[i]}') as f:\n",
    "            file = f.read()\n",
    "            file = file.splitlines()\n",
    "\n",
    "        xmin = int(re.split(\"\\t|</xmin>|<xmin>\", file[19])[-2])\n",
    "        ymin = int(re.split(\"\\t|</ymin>|<ymin>\", file[20])[-2])\n",
    "        xmax = int(re.split(\"\\t|</xmax>|<xmax>\", file[21])[-2])\n",
    "        ymax = int(re.split(\"\\t|</ymax>|<ymax>\", file[22])[-2])\n",
    "        \n",
    "        with open(f\"{label_txt}{label_xml[i].split('.xml')[0]}.txt\", 'w') as f:\n",
    "            \n",
    "            # Change the below line code format in case you wanted to use another model\n",
    "            f.write(f\"{label_id} {xmin} {ymin} {xmax} {ymax}\")\n",
    "    \n",
    "    return(print(\"Operation was successful!\"))\n",
    "\n",
    "# Reminder: classes = [{'Name':'Rock', 'id':0}, {'Name':'Paper', 'id':1}, {'Name':'Scissors', 'id':2}]\n",
    "rock_xml = os.listdir(rock_labels_path)\n",
    "paper_xml = os.listdir(paper_labels_path)\n",
    "scissors_xml = os.listdir(scissors_labels_path)\n",
    "\n",
    "rock_txt_path = os.path.join(\"Dataset/Texts/Rock/\")\n",
    "paper_txt_path = os.path.join(\"Dataset/Texts/Paper/\")\n",
    "scissors_txt_path = os.path.join(\"Dataset/Texts/Scissors/\")\n",
    "\n",
    "xml_to_txt(rock_xml, rock_labels_path, rock_txt_path, 0)\n",
    "xml_to_txt(paper_xml, paper_labels_path, paper_txt_path, 1)\n",
    "xml_to_txt(scissors_xml, scissors_labels_path, scissors_txt_path, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle_drawer(file_name, label_path, image_path):\n",
    "    with open(f\"{label_path}{file_name}.txt\") as f:\n",
    "        coords = f.read().split()\n",
    "    \n",
    "    image = cv.imread(f\"{image_path}{file_name}.jpg\")\n",
    "    \n",
    "    # Extract top-left and bottom-right points\n",
    "    top_left = (int(coords[1]), int(coords[2]))\n",
    "    bottom_right = (int(coords[3]), int(coords[4]))\n",
    "\n",
    "    # Draw rectangle on the image\n",
    "    image = cv.rectangle(image, top_left, bottom_right, (0, 255, 0), 5)\n",
    "    return(image)\n",
    "\n",
    "rock_test_img = rectangle_drawer(\"34d591ed-6516-11ef-9f12-a289da6cb5d8\", rock_txt_path, rock_images_path)\n",
    "paper_test_img = rectangle_drawer(\"5356c03a-6515-11ef-a75b-a289da6cb5d8\", paper_txt_path, paper_images_path)\n",
    "scissors_test_img = rectangle_drawer(\"03d68a77-6516-11ef-9436-a289da6cb5d8\", scissors_txt_path, scissors_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae622bd0",
   "metadata": {},
   "source": [
    "### 4- Testing the boundary boxes that we've created early using \"LabelImg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(cv.cvtColor(rock_test_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Rock\", c='green')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(cv.cvtColor(paper_test_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Paper\", c='green')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(cv.cvtColor(scissors_test_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Scissors\", c='green')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfa99c",
   "metadata": {},
   "source": [
    "Since the standard Yolo-Annotation format includes a \".txt\" file which has:\n",
    "#### * class_name -> x-center -> y-center -> width -> height\n",
    "we have to change the values of text files\n",
    "\n",
    "### Caution: label values should become normalized to use for \"YOLO\"\n",
    "\n",
    "\n",
    "# RUN THE BELOW CELL ONLY ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All images are in the same shape\n",
    "image = cv.imread(\"Dataset/Images/Rock/32cb2d4f-6516-11ef-b2d1-a289da6cb5d8.jpg\")\n",
    "h_img, w_img, channel = image.shape\n",
    "\n",
    "text_folder = os.listdir(os.path.join(\"Dataset/Texts/\"))\n",
    "\n",
    "for i in range(len(text_folder)):\n",
    "    text_files = os.listdir(os.path.join(f\"Dataset/Texts/{text_folder[i]}\"))\n",
    "    for j in range(len(text_files)):\n",
    "        with open(f\"Dataset/Texts/{text_folder[i]}/{text_files[j]}\") as f:\n",
    "            # Label - xmin - ymin - xmax - ymax\n",
    "            file = list(map(int, f.read().split()))\n",
    "        \n",
    "        label = file[0]\n",
    "        w_box = (file[3] - file[1])\n",
    "        h_box = (file[4] - file[2])\n",
    "        x_center = (file[1] + w_box / 2) / w_img\n",
    "        y_center = (file[2] + h_box / 2) / h_img\n",
    "        w_box = w_box / w_img\n",
    "        h_box = h_box / h_img\n",
    "        with open(f\"Dataset/Texts/{text_folder[i]}/{text_files[j]}\", 'w') as f:\n",
    "            f.write(f\"{label} {x_center} {y_center} {w_box} {h_box}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750999c",
   "metadata": {},
   "source": [
    "#### How to build \"Yolo-setup.yaml\" file:\n",
    "1. (Optional): Create a folder for the config and train weights\n",
    "2. Create \"Yolo-setup.yaml\" file\n",
    "3. Define path, train, val & names for your problem\n",
    "4. Put the 'path' of where your python code and dataset is\n",
    "5. Put the path of your images in train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee89d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now cather all datas in a single folder\n",
    "\n",
    "# os.mkdir(\"Yolo-Data/\")\n",
    "# os.mkdir(\"Yolo-Data/train/\")\n",
    "# os.mkdir(\"Yolo-Data/val/\")\n",
    "# os.mkdir(\"Yolo-Data/train/images\")\n",
    "# os.mkdir(\"Yolo-Data/train/labels\")\n",
    "# os.mkdir(\"Yolo-Data/val/images\")\n",
    "# os.mkdir(\"Yolo-Data/val/labels\")\n",
    "\n",
    "def yolo_annotator(folder_path, file_type=0):\n",
    "    for i in tqdm_notebook(range(len(os.listdir(folder_path)))):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file_type == 0 or file_type == 'image':\n",
    "                shutil.copy(f\"{folder_path}{file}\", \"Yolo-Data/train/images\")\n",
    "                \n",
    "            elif file_type == 1 or file_type == 'label':\n",
    "                shutil.copy(f\"{folder_path}{file}\", \"Yolo-Data/train/labels\")\n",
    "    \n",
    "yolo_annotator(rock_images_path, 0)\n",
    "yolo_annotator(paper_images_path, 0)\n",
    "yolo_annotator(scissors_images_path, 0)\n",
    "\n",
    "yolo_annotator(rock_txt_path, 1)\n",
    "yolo_annotator(paper_txt_path, 1)\n",
    "yolo_annotator(scissors_txt_path, 1)\n",
    "\n",
    "for _ in range(20):\n",
    "    random_img = random.choice(os.listdir(os.path.join(\"Yolo-Data/train/images/\")))\n",
    "    shutil.move(f\"Yolo-Data/train/images/{random_img}\", f\"Yolo-Data/val/images/{random_img}\")\n",
    "    random_lbl = random_img.split(\".jpg\")[0]+'.txt'\n",
    "    shutil.move(f\"Yolo-Data/train/labels/{random_lbl}\", f\"Yolo-Data/val/labels/{random_lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c162e5",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "* I recommend you to train the model with more datasets and epochs to get better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbca62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring .yaml file for the pathes of each class for training the YOLO model\n",
    "with open(\"setting.yaml\", 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "path: /Users/Sina/Desktop/Summer Projects/Rock Paper Scissors/Yolo-Data\n",
    "train: train/images\n",
    "val: val/images\n",
    "\n",
    "nc: 3\n",
    "names:\n",
    "    0: Rock\n",
    "    1: Paper\n",
    "    2: Scissors\n",
    "\"\"\")\n",
    "\n",
    "# It's possible to use torch to load YOLO model but i recommend you to use it the same way i did\n",
    "model = YOLO(\"yolov5s.pt\")\n",
    "results = model.train(data=\"setting.yaml\", epochs=50, imgsz=640)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.10",
   "language": "python",
   "name": "python-3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
